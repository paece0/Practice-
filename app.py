import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

st.set_page_config(page_title="å€‹æ€§åŒ–èŠå¤© AI", page_icon="ğŸ§ ")
st.title("ğŸ§  å€‹æ€§åŒ–èŠå¤© AI")

@st.cache_resource
def load_model():
    model_name = "distilgpt2"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    return tokenizer, model

tokenizer, model = load_model()

# åˆå§‹åŒ–ç‹€æ…‹
if "persona" not in st.session_state:
    st.session_state.persona = ""
if "messages" not in st.session_state:
    st.session_state.messages = []

# è¨­å®š AI å€‹æ€§
if not st.session_state.persona:
    st.session_state.persona = st.text_input("è«‹å…ˆè¼¸å…¥ AI çš„å€‹æ€§ï¼ˆä¾‹å¦‚ï¼šé¢¨è¶£å¹½é»˜ã€å†·éœåˆ†æï¼‰")
    if not st.session_state.persona:
        st.stop()
    st.success("âœ… å€‹æ€§è¨­å®šæˆåŠŸï¼é–‹å§‹å°è©±å§")

# é¡¯ç¤ºå°è©±æ­·å²
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar="ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"):
        st.markdown(msg["content"])

# ä½¿ç”¨è€…è¼¸å…¥
user_input = st.chat_input("ä½ æƒ³èªªä»€éº¼ï¼Ÿ")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(user_input)

    # å¼·åŒ– Promptï¼Œé™åˆ¶å›è¦†åªèˆ‡å°è©±æœ‰é—œï¼Œä¸”é¿å…è™›æ§‹
    full_prompt = (
        f"ä½ æ˜¯ä¸€å€‹é¢¨æ ¼ç‚ºã€Œ{st.session_state.persona}ã€çš„èŠå¤© AIã€‚"
        "è«‹ç”¨è‡ªç„¶ã€è¦ªåˆ‡ä¸”ç°¡æ½”çš„èªè¨€å›ç­”ä½¿ç”¨è€…çš„å•é¡Œã€‚"
        "ä¸è¦æä¾›æœªç¶“è­‰å¯¦çš„è³‡è¨Šæˆ–æ•…äº‹ï¼Œåªæ ¹æ“šä½¿ç”¨è€…çš„è¼¸å…¥å›ç­”ã€‚"
        f"\n\nä½¿ç”¨è€…èªªï¼šã€Œ{user_input}ã€\nAI å›æ‡‰ï¼š"
    )

    input_ids = tokenizer.encode(full_prompt, return_tensors="pt")

    output_ids = model.generate(
        input_ids,
        max_length=150,
        pad_token_id=tokenizer.eos_token_id,
        do_sample=True,
        top_k=40,
        top_p=0.85,
        temperature=0.7,
        no_repeat_ngram_size=3,
        early_stopping=True
    )

    response = tokenizer.decode(output_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True).strip()

    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        st.markdown(response)

# é‡æ–°é–‹å§‹æŒ‰éˆ•
if st.button("ğŸ”„ é‡æ–°é–‹å§‹å°è©±"):
    st.session_state.messages = []
    st.session_state.persona = ""
    st.experimental_rerun()
