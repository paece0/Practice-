import streamlit as st
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

st.set_page_config(page_title="å€‹æ€§åŒ–èŠå¤© AI", page_icon="ğŸ§ ")
st.title("ğŸ§  å€‹æ€§åŒ–èŠå¤© AI")

# è¼‰å…¥æ¨¡å‹ï¼ˆåªåŸ·è¡Œä¸€æ¬¡ï¼‰
@st.cache_resource
def load_model():
    model_name = "distilgpt2"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    return tokenizer, model

tokenizer, model = load_model()

# åˆå§‹åŒ–ç‹€æ…‹
if "persona" not in st.session_state:
    st.session_state.persona = ""
if "messages" not in st.session_state:
    st.session_state.messages = []

# å€‹æ€§è¼¸å…¥
if not st.session_state.persona:
    st.session_state.persona = st.text_input("è«‹å…ˆè¼¸å…¥ AI çš„å€‹æ€§ï¼ˆä¾‹å¦‚ï¼šé¢¨è¶£å¹½é»˜ã€å†·éœåˆ†æï¼‰")
    if not st.session_state.persona:
        st.stop()
    st.success("âœ… å€‹æ€§è¨­å®šæˆåŠŸï¼é–‹å§‹å°è©±å§")

# é¡¯ç¤ºæ­·å²å°è©±ï¼ˆæœ‰é ­åƒï¼‰
for msg in st.session_state.messages:
    with st.chat_message(msg["role"], avatar="ğŸ§‘" if msg["role"] == "user" else "ğŸ¤–"):
        st.markdown(msg["content"])

# ä½¿ç”¨ chat_input è¼¸å…¥
user_input = st.chat_input("ä½ æƒ³èªªä»€éº¼ï¼Ÿ")
if user_input:
    # é¡¯ç¤ºä½¿ç”¨è€…è¨Šæ¯
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user", avatar="ğŸ§‘"):
        st.markdown(user_input)

    # è£½ä½œå®Œæ•´ promptï¼ŒåŠ å¼·æŒ‡ä»¤é¿å…è·‘é¡Œ
    full_prompt = (
        f"ä½ æ˜¯ä¸€å€‹{st.session_state.persona}é¢¨æ ¼çš„ AIï¼Œè«‹é‡å°ä½¿ç”¨è€…å•é¡Œç›´æ¥å›æ‡‰ï¼Œé¿å…é›¢é¡Œæˆ–å»¢è©±ã€‚\n\n"
        f"ä½¿ç”¨è€…å•ï¼šã€Œ{user_input}ã€\n"
        f"AI å›ç­”ï¼š"
    )
    input_ids = tokenizer.encode(full_prompt, return_tensors="pt")

    # æ¨¡å‹ç”Ÿæˆ
    output_ids = model.generate(
        input_ids,
        max_length=256,
        pad_token_id=tokenizer.eos_token_id,
        do_sample=True,
        top_k=50,
        top_p=0.9,
        temperature=0.7
    )
    response = tokenizer.decode(output_ids[:, input_ids.shape[-1]:][0], skip_special_tokens=True)

    # é¡¯ç¤º AI å›æ‡‰
    st.session_state.messages.append({"role": "assistant", "content": response})
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        st.markdown(response)

# é‡æ–°é–‹å§‹æŒ‰éˆ•
if st.button("ğŸ”„ é‡æ–°é–‹å§‹å°è©±"):
    st.session_state.messages = []
    st.session_state.persona = ""
    st.experimental_rerun()
